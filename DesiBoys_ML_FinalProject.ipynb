{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ec8924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/cent7/jupyterhub/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-02-19 20:49:58.435585: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-19 20:49:58.435640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-19 20:49:58.436605: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-19 20:49:58.442812: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-19 20:49:59.446620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ccea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              id        item_id    dept_id   cat_id store_id  \\\n",
      "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
      "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
      "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
      "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
      "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
      "\n",
      "  state_id  d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
      "0       CA    0    0    0    0  ...       2       4       0       0       0   \n",
      "1       CA    0    0    0    0  ...       0       1       2       1       1   \n",
      "2       CA    0    0    0    0  ...       1       0       2       0       0   \n",
      "3       CA    0    0    0    0  ...       1       1       0       4       0   \n",
      "4       CA    0    0    0    0  ...       0       0       0       2       1   \n",
      "\n",
      "   d_1937  d_1938  d_1939  d_1940  d_1941  \n",
      "0       0       3       3       0       1  \n",
      "1       0       0       0       0       0  \n",
      "2       0       2       3       0       1  \n",
      "3       1       3       0       2       6  \n",
      "4       0       0       2       1       0  \n",
      "\n",
      "[5 rows x 1947 columns]\n",
      "  store_id        item_id  wm_yr_wk  sell_price\n",
      "0     CA_1  HOBBIES_1_001     11325        9.58\n",
      "1     CA_1  HOBBIES_1_001     11326        9.58\n",
      "2     CA_1  HOBBIES_1_001     11327        8.26\n",
      "3     CA_1  HOBBIES_1_001     11328        8.26\n",
      "4     CA_1  HOBBIES_1_001     11329        8.26\n",
      "         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
      "0  2011-01-29     11101   Saturday     1      1  2011  d_1          NaN   \n",
      "1  2011-01-30     11101     Sunday     2      1  2011  d_2          NaN   \n",
      "2  2011-01-31     11101     Monday     3      1  2011  d_3          NaN   \n",
      "3  2011-02-01     11101    Tuesday     4      2  2011  d_4          NaN   \n",
      "4  2011-02-02     11101  Wednesday     5      2  2011  d_5          NaN   \n",
      "\n",
      "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
      "0          NaN          NaN          NaN        0        0        0  \n",
      "1          NaN          NaN          NaN        0        0        0  \n",
      "2          NaN          NaN          NaN        0        0        0  \n",
      "3          NaN          NaN          NaN        1        1        0  \n",
      "4          NaN          NaN          NaN        1        0        1  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "sales_train = pd.read_csv('sales_train_evaluation.csv')\n",
    "sell_prices = pd.read_csv('sell_prices.csv')\n",
    "calendar = pd.read_csv('calendar.csv')\n",
    "print(sales_train.head())\n",
    "print(sell_prices.head())\n",
    "print(calendar.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a08fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downcast data types to reduce memory usage\n",
    "def downcast_dtypes(df):\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int16)\n",
    "    return df\n",
    "\n",
    "sales_train = downcast_dtypes(sales_train)\n",
    "sell_prices = downcast_dtypes(sell_prices)\n",
    "calendar = downcast_dtypes(calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6a117b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.298076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.967459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.965734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.502845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.880902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1948 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1933  d_1934  d_1935  d_1936  d_1937  \\\n",
       "0       CA    0    0    0    0  ...       4       0       0       0       0   \n",
       "1       CA    0    0    0    0  ...       1       2       1       1       0   \n",
       "2       CA    0    0    0    0  ...       0       2       0       0       0   \n",
       "3       CA    0    0    0    0  ...       1       0       4       0       1   \n",
       "4       CA    0    0    0    0  ...       0       0       2       1       0   \n",
       "\n",
       "   d_1938  d_1939  d_1940  d_1941  sell_price  \n",
       "0       3       3       0       1    8.298076  \n",
       "1       0       0       0       0    3.967459  \n",
       "2       2       3       0       1    2.965734  \n",
       "3       3       0       2       6    4.502845  \n",
       "4       0       2       1       0    2.880902  \n",
       "\n",
       "[5 rows x 1948 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique feature: Calculate average sales price per product\n",
    "average_price = sell_prices.groupby('item_id')['sell_price'].mean().reset_index()\n",
    "sales_train = pd.merge(sales_train, average_price, on='item_id', how='left')\n",
    "\n",
    "sales_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb1645b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ca03e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7321/3630898340.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train['total_sales'] = sales_train.loc[:, 'd_345':'d_1941'].sum(axis=1)\n",
      "/tmp/ipykernel_7321/3630898340.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train[f'sales_lag_{i}'] = sales_train['total_sales'].shift(i)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1941</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>sales_lag_1</th>\n",
       "      <th>sales_lag_2</th>\n",
       "      <th>sales_lag_3</th>\n",
       "      <th>sales_lag_4</th>\n",
       "      <th>sales_lag_5</th>\n",
       "      <th>sales_lag_6</th>\n",
       "      <th>sales_lag_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8.298076</td>\n",
       "      <td>633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.967459</td>\n",
       "      <td>441</td>\n",
       "      <td>633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.965734</td>\n",
       "      <td>309</td>\n",
       "      <td>441.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4.502845</td>\n",
       "      <td>2903</td>\n",
       "      <td>309.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.880902</td>\n",
       "      <td>1608</td>\n",
       "      <td>2903.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1956 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1941  sell_price  total_sales  \\\n",
       "0       CA    0    0    0    0  ...       1    8.298076          633   \n",
       "1       CA    0    0    0    0  ...       0    3.967459          441   \n",
       "2       CA    0    0    0    0  ...       1    2.965734          309   \n",
       "3       CA    0    0    0    0  ...       6    4.502845         2903   \n",
       "4       CA    0    0    0    0  ...       0    2.880902         1608   \n",
       "\n",
       "   sales_lag_1  sales_lag_2  sales_lag_3  sales_lag_4  sales_lag_5  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1        633.0          0.0          0.0          0.0          0.0   \n",
       "2        441.0        633.0          0.0          0.0          0.0   \n",
       "3        309.0        441.0        633.0          0.0          0.0   \n",
       "4       2903.0        309.0        441.0        633.0          0.0   \n",
       "\n",
       "   sales_lag_6  sales_lag_7  \n",
       "0          0.0          0.0  \n",
       "1          0.0          0.0  \n",
       "2          0.0          0.0  \n",
       "3          0.0          0.0  \n",
       "4          0.0          0.0  \n",
       "\n",
       "[5 rows x 1956 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Feature Engineering for calendar dataframe\n",
    "if 'date' in calendar.columns:\n",
    "    calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "    calendar['day_of_week'] = calendar['date'].dt.dayofweek\n",
    "    calendar['month'] = calendar['date'].dt.month\n",
    "    calendar['year'] = calendar['date'].dt.year\n",
    "else:\n",
    "    raise ValueError(\"Error: 'date' column not found in the calendar dataframe.\")\n",
    "\n",
    "# Feature Engineering for sales_train dataframe\n",
    "if all(col in sales_train.columns for col in ['d_345', 'd_1941']):\n",
    "    # Summing up sales data across columns 'd_345' to 'd_1941'\n",
    "    sales_train['total_sales'] = sales_train.loc[:, 'd_345':'d_1941'].sum(axis=1)\n",
    "    # Create lag features\n",
    "    for i in range(1, 8):\n",
    "        sales_train[f'sales_lag_{i}'] = sales_train['total_sales'].shift(i)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Error: Columns 'd_345' to 'd_1941' are required for summing up sales data.\")\n",
    "\n",
    "# Handle missing values consistently\n",
    "sales_train.fillna(0, inplace=True)\n",
    "calendar.fillna(0, inplace=True)\n",
    "\n",
    "# Transpose the sales_train DataFrame\n",
    "sales_train_transposed = sales_train.T\n",
    "\n",
    "# Select data for the past year only\n",
    "last_year_sales = sales_train.iloc[:, -365:]\n",
    "last_year_calendar = calendar.iloc[-365:]\n",
    "\n",
    "# Scale features\n",
    "numeric_columns = [col for col in last_year_sales.columns if col not in ['date', 'd', 'total_sales']]\n",
    "if numeric_columns:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_sales = scaler.fit_transform(last_year_sales[numeric_columns])\n",
    "else:\n",
    "    raise ValueError(\"Error: No numeric columns found for scaling.\")\n",
    "\n",
    "timesteps=7\n",
    "sales_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167725dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_size = int(len(scaled_sales) * 0.8)\n",
    "test_size = len(scaled_sales) - train_size\n",
    "train, test = scaled_sales[0:train_size,:], scaled_sales[train_size:len(scaled_sales),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e893de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, timesteps=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-timesteps):\n",
    "        a = dataset[i:(i+timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + timesteps, :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "X_train, y_train = create_dataset(train, timesteps)\n",
    "X_test, y_test = create_dataset(test, timesteps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83cb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from tensorflow.keras.activations import relu\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if logs.get('loss') is not None and np.isnan(logs.get('loss')):\n",
    "            print('Batch %d: Invalid loss, terminating training' % (batch))\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "762d3df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 7, 256)            635904    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 256)            0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 7, 256)            1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 7, 128)            197120    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 364)               23660     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 907372 (3.46 MB)\n",
      "Trainable params: 906732 (3.46 MB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D\n",
    "\n",
    "n_features = scaled_sales.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(256, return_sequences=True, input_shape=(timesteps, n_features)),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(), \n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),\n",
    "    BatchNormalization(),\n",
    "    Dense(364)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58c79814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gradient clipping in the optimizer\n",
    "optimizer = Adam(learning_rate=0.001, clipvalue=0.5)\n",
    "model.compile(optimizer=optimizer, loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf48f20e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "267/267 - 11s - loss: 37.7558 - val_loss: 37.6844 - 11s/epoch - 43ms/step\n",
      "Epoch 2/150\n",
      "267/267 - 8s - loss: 37.3186 - val_loss: 36.9894 - 8s/epoch - 28ms/step\n",
      "Epoch 3/150\n",
      "267/267 - 7s - loss: 36.4419 - val_loss: 35.8233 - 7s/epoch - 28ms/step\n",
      "Epoch 4/150\n",
      "267/267 - 8s - loss: 35.2224 - val_loss: 35.0522 - 8s/epoch - 28ms/step\n",
      "Epoch 5/150\n",
      "267/267 - 7s - loss: 33.7575 - val_loss: 32.5225 - 7s/epoch - 28ms/step\n",
      "Epoch 6/150\n",
      "267/267 - 7s - loss: 32.2855 - val_loss: 31.7174 - 7s/epoch - 28ms/step\n",
      "Epoch 7/150\n",
      "267/267 - 7s - loss: 30.9571 - val_loss: 30.7414 - 7s/epoch - 28ms/step\n",
      "Epoch 8/150\n",
      "267/267 - 8s - loss: 29.8609 - val_loss: 29.4762 - 8s/epoch - 29ms/step\n",
      "Epoch 9/150\n",
      "267/267 - 8s - loss: 29.0152 - val_loss: 29.9290 - 8s/epoch - 29ms/step\n",
      "Epoch 10/150\n",
      "267/267 - 8s - loss: 28.3892 - val_loss: 28.7982 - 8s/epoch - 28ms/step\n",
      "Epoch 11/150\n",
      "267/267 - 8s - loss: 27.9410 - val_loss: 28.4602 - 8s/epoch - 28ms/step\n",
      "Epoch 12/150\n",
      "267/267 - 8s - loss: 27.6333 - val_loss: 28.2265 - 8s/epoch - 28ms/step\n",
      "Epoch 13/150\n",
      "267/267 - 8s - loss: 27.4313 - val_loss: 28.1788 - 8s/epoch - 29ms/step\n",
      "Epoch 14/150\n",
      "267/267 - 7s - loss: 27.2981 - val_loss: 28.1201 - 7s/epoch - 27ms/step\n",
      "Epoch 15/150\n",
      "267/267 - 8s - loss: 27.2047 - val_loss: 28.1017 - 8s/epoch - 28ms/step\n",
      "Epoch 16/150\n",
      "267/267 - 7s - loss: 27.1455 - val_loss: 28.1315 - 7s/epoch - 27ms/step\n",
      "Epoch 17/150\n",
      "267/267 - 8s - loss: 27.1118 - val_loss: 28.1429 - 8s/epoch - 29ms/step\n",
      "Epoch 18/150\n",
      "267/267 - 7s - loss: 27.0648 - val_loss: 28.0871 - 7s/epoch - 28ms/step\n",
      "Epoch 19/150\n",
      "267/267 - 7s - loss: 27.0376 - val_loss: 28.0608 - 7s/epoch - 28ms/step\n",
      "Epoch 20/150\n",
      "267/267 - 8s - loss: 26.9748 - val_loss: 28.0890 - 8s/epoch - 29ms/step\n",
      "Epoch 21/150\n",
      "267/267 - 8s - loss: 26.9185 - val_loss: 27.9665 - 8s/epoch - 28ms/step\n",
      "Epoch 22/150\n",
      "267/267 - 8s - loss: 26.8364 - val_loss: 27.8765 - 8s/epoch - 28ms/step\n",
      "Epoch 23/150\n",
      "267/267 - 7s - loss: 26.7296 - val_loss: 27.7796 - 7s/epoch - 28ms/step\n",
      "Epoch 24/150\n",
      "267/267 - 7s - loss: 26.6038 - val_loss: 27.6484 - 7s/epoch - 28ms/step\n",
      "Epoch 25/150\n",
      "267/267 - 8s - loss: 26.4895 - val_loss: 27.4978 - 8s/epoch - 28ms/step\n",
      "Epoch 26/150\n",
      "267/267 - 8s - loss: 26.3754 - val_loss: 27.3637 - 8s/epoch - 30ms/step\n",
      "Epoch 27/150\n",
      "267/267 - 8s - loss: 26.2259 - val_loss: 27.3257 - 8s/epoch - 30ms/step\n",
      "Epoch 28/150\n",
      "267/267 - 8s - loss: 26.0945 - val_loss: 27.1797 - 8s/epoch - 29ms/step\n",
      "Epoch 29/150\n",
      "267/267 - 8s - loss: 25.9422 - val_loss: 27.0103 - 8s/epoch - 29ms/step\n",
      "Epoch 30/150\n",
      "267/267 - 8s - loss: 25.7825 - val_loss: 26.8394 - 8s/epoch - 28ms/step\n",
      "Epoch 31/150\n",
      "267/267 - 7s - loss: 25.6429 - val_loss: 26.6709 - 7s/epoch - 28ms/step\n",
      "Epoch 32/150\n",
      "267/267 - 8s - loss: 25.4490 - val_loss: 26.5059 - 8s/epoch - 29ms/step\n",
      "Epoch 33/150\n",
      "267/267 - 8s - loss: 25.2611 - val_loss: 26.3920 - 8s/epoch - 29ms/step\n",
      "Epoch 34/150\n",
      "267/267 - 8s - loss: 25.0853 - val_loss: 26.1314 - 8s/epoch - 28ms/step\n",
      "Epoch 35/150\n",
      "267/267 - 7s - loss: 24.8718 - val_loss: 26.1032 - 7s/epoch - 28ms/step\n",
      "Epoch 36/150\n",
      "267/267 - 8s - loss: 24.6685 - val_loss: 25.7851 - 8s/epoch - 29ms/step\n",
      "Epoch 37/150\n",
      "267/267 - 8s - loss: 24.4296 - val_loss: 25.5121 - 8s/epoch - 29ms/step\n",
      "Epoch 38/150\n",
      "267/267 - 7s - loss: 24.1994 - val_loss: 25.2827 - 7s/epoch - 28ms/step\n",
      "Epoch 39/150\n",
      "267/267 - 7s - loss: 23.9592 - val_loss: 25.0393 - 7s/epoch - 28ms/step\n",
      "Epoch 40/150\n",
      "267/267 - 7s - loss: 23.7099 - val_loss: 24.7581 - 7s/epoch - 28ms/step\n",
      "Epoch 41/150\n",
      "267/267 - 8s - loss: 23.4660 - val_loss: 24.4695 - 8s/epoch - 28ms/step\n",
      "Epoch 42/150\n",
      "267/267 - 8s - loss: 23.1564 - val_loss: 24.2511 - 8s/epoch - 28ms/step\n",
      "Epoch 43/150\n",
      "267/267 - 8s - loss: 22.8762 - val_loss: 23.8913 - 8s/epoch - 28ms/step\n",
      "Epoch 44/150\n",
      "267/267 - 8s - loss: 22.5993 - val_loss: 23.5638 - 8s/epoch - 28ms/step\n",
      "Epoch 45/150\n",
      "267/267 - 7s - loss: 22.2854 - val_loss: 23.3242 - 7s/epoch - 28ms/step\n",
      "Epoch 46/150\n",
      "267/267 - 8s - loss: 22.0010 - val_loss: 23.0132 - 8s/epoch - 29ms/step\n",
      "Epoch 47/150\n",
      "267/267 - 8s - loss: 21.6780 - val_loss: 22.6881 - 8s/epoch - 28ms/step\n",
      "Epoch 48/150\n",
      "267/267 - 7s - loss: 21.3514 - val_loss: 22.4004 - 7s/epoch - 27ms/step\n",
      "Epoch 49/150\n",
      "267/267 - 7s - loss: 21.0426 - val_loss: 22.1206 - 7s/epoch - 28ms/step\n",
      "Epoch 50/150\n",
      "267/267 - 7s - loss: 20.6585 - val_loss: 21.6079 - 7s/epoch - 28ms/step\n",
      "Epoch 51/150\n",
      "267/267 - 8s - loss: 20.2668 - val_loss: 21.1674 - 8s/epoch - 29ms/step\n",
      "Epoch 52/150\n",
      "267/267 - 8s - loss: 19.8529 - val_loss: 20.8242 - 8s/epoch - 28ms/step\n",
      "Epoch 53/150\n",
      "267/267 - 8s - loss: 19.4725 - val_loss: 20.1353 - 8s/epoch - 29ms/step\n",
      "Epoch 54/150\n",
      "267/267 - 9s - loss: 19.0970 - val_loss: 19.6253 - 9s/epoch - 32ms/step\n",
      "Epoch 55/150\n",
      "267/267 - 9s - loss: 18.6694 - val_loss: 19.1378 - 9s/epoch - 34ms/step\n",
      "Epoch 56/150\n",
      "267/267 - 9s - loss: 18.2189 - val_loss: 18.6081 - 9s/epoch - 34ms/step\n",
      "Epoch 57/150\n",
      "267/267 - 9s - loss: 17.8079 - val_loss: 18.1515 - 9s/epoch - 36ms/step\n",
      "Epoch 58/150\n",
      "267/267 - 9s - loss: 17.3444 - val_loss: 17.6715 - 9s/epoch - 33ms/step\n",
      "Epoch 59/150\n",
      "267/267 - 8s - loss: 16.9653 - val_loss: 16.9691 - 8s/epoch - 31ms/step\n",
      "Epoch 60/150\n",
      "267/267 - 8s - loss: 16.4443 - val_loss: 16.3735 - 8s/epoch - 30ms/step\n",
      "Epoch 61/150\n",
      "267/267 - 8s - loss: 16.0891 - val_loss: 16.3661 - 8s/epoch - 29ms/step\n",
      "Epoch 62/150\n",
      "267/267 - 8s - loss: 15.7628 - val_loss: 15.9362 - 8s/epoch - 29ms/step\n",
      "Epoch 63/150\n",
      "267/267 - 8s - loss: 15.4302 - val_loss: 15.3292 - 8s/epoch - 29ms/step\n",
      "Epoch 64/150\n",
      "267/267 - 8s - loss: 15.1129 - val_loss: 15.0339 - 8s/epoch - 29ms/step\n",
      "Epoch 65/150\n",
      "267/267 - 8s - loss: 14.7749 - val_loss: 14.4954 - 8s/epoch - 29ms/step\n",
      "Epoch 66/150\n",
      "267/267 - 8s - loss: 14.6425 - val_loss: 14.3757 - 8s/epoch - 29ms/step\n",
      "Epoch 67/150\n",
      "267/267 - 7s - loss: 14.3214 - val_loss: 14.5382 - 7s/epoch - 28ms/step\n",
      "Epoch 68/150\n",
      "267/267 - 7s - loss: 14.1293 - val_loss: 13.8820 - 7s/epoch - 28ms/step\n",
      "Epoch 69/150\n",
      "267/267 - 8s - loss: 13.8251 - val_loss: 13.4248 - 8s/epoch - 29ms/step\n",
      "Epoch 70/150\n",
      "267/267 - 8s - loss: 13.7379 - val_loss: 12.9186 - 8s/epoch - 28ms/step\n",
      "Epoch 71/150\n",
      "267/267 - 7s - loss: 13.4879 - val_loss: 12.8929 - 7s/epoch - 28ms/step\n",
      "Epoch 72/150\n",
      "267/267 - 7s - loss: 13.3034 - val_loss: 13.0387 - 7s/epoch - 27ms/step\n",
      "Epoch 73/150\n",
      "267/267 - 7s - loss: 13.1830 - val_loss: 13.5545 - 7s/epoch - 28ms/step\n",
      "Epoch 74/150\n",
      "267/267 - 7s - loss: 12.9787 - val_loss: 13.5227 - 7s/epoch - 27ms/step\n",
      "Epoch 75/150\n",
      "267/267 - 7s - loss: 12.8608 - val_loss: 11.7725 - 7s/epoch - 28ms/step\n",
      "Epoch 76/150\n",
      "267/267 - 8s - loss: 12.6534 - val_loss: 11.7438 - 8s/epoch - 29ms/step\n",
      "Epoch 77/150\n",
      "267/267 - 8s - loss: 12.5580 - val_loss: 11.5906 - 8s/epoch - 29ms/step\n",
      "Epoch 78/150\n",
      "267/267 - 7s - loss: 12.5275 - val_loss: 11.9723 - 7s/epoch - 27ms/step\n",
      "Epoch 79/150\n",
      "267/267 - 8s - loss: 12.3280 - val_loss: 11.5793 - 8s/epoch - 28ms/step\n",
      "Epoch 80/150\n",
      "267/267 - 8s - loss: 12.2610 - val_loss: 11.1473 - 8s/epoch - 29ms/step\n",
      "Epoch 81/150\n",
      "267/267 - 8s - loss: 12.1195 - val_loss: 11.5101 - 8s/epoch - 28ms/step\n",
      "Epoch 82/150\n",
      "267/267 - 8s - loss: 11.9461 - val_loss: 11.2024 - 8s/epoch - 30ms/step\n",
      "Epoch 83/150\n",
      "267/267 - 7s - loss: 11.8485 - val_loss: 10.5893 - 7s/epoch - 27ms/step\n",
      "Epoch 84/150\n",
      "267/267 - 8s - loss: 11.8582 - val_loss: 10.9358 - 8s/epoch - 29ms/step\n",
      "Epoch 85/150\n",
      "267/267 - 8s - loss: 11.7922 - val_loss: 11.4543 - 8s/epoch - 29ms/step\n",
      "Epoch 86/150\n",
      "267/267 - 8s - loss: 11.7004 - val_loss: 10.6217 - 8s/epoch - 29ms/step\n",
      "Epoch 87/150\n",
      "267/267 - 8s - loss: 11.6966 - val_loss: 10.4463 - 8s/epoch - 29ms/step\n",
      "Epoch 88/150\n",
      "267/267 - 8s - loss: 11.7193 - val_loss: 10.5225 - 8s/epoch - 30ms/step\n",
      "Epoch 89/150\n",
      "267/267 - 8s - loss: 11.5918 - val_loss: 11.1013 - 8s/epoch - 29ms/step\n",
      "Epoch 90/150\n",
      "267/267 - 8s - loss: 11.5174 - val_loss: 11.6603 - 8s/epoch - 29ms/step\n",
      "Epoch 91/150\n",
      "267/267 - 8s - loss: 11.4219 - val_loss: 10.4051 - 8s/epoch - 28ms/step\n",
      "Epoch 92/150\n",
      "267/267 - 8s - loss: 11.3831 - val_loss: 10.4885 - 8s/epoch - 28ms/step\n",
      "Epoch 93/150\n",
      "267/267 - 8s - loss: 11.4211 - val_loss: 10.3665 - 8s/epoch - 29ms/step\n",
      "Epoch 94/150\n",
      "267/267 - 8s - loss: 11.4525 - val_loss: 10.1642 - 8s/epoch - 29ms/step\n",
      "Epoch 95/150\n",
      "267/267 - 8s - loss: 11.2400 - val_loss: 10.5120 - 8s/epoch - 29ms/step\n",
      "Epoch 96/150\n",
      "267/267 - 8s - loss: 11.2143 - val_loss: 9.4553 - 8s/epoch - 29ms/step\n",
      "Epoch 97/150\n",
      "267/267 - 8s - loss: 11.2183 - val_loss: 9.7421 - 8s/epoch - 29ms/step\n",
      "Epoch 98/150\n",
      "267/267 - 8s - loss: 11.2080 - val_loss: 9.8884 - 8s/epoch - 30ms/step\n",
      "Epoch 99/150\n",
      "267/267 - 8s - loss: 11.1201 - val_loss: 9.6559 - 8s/epoch - 31ms/step\n",
      "Epoch 100/150\n",
      "267/267 - 8s - loss: 11.2268 - val_loss: 11.0486 - 8s/epoch - 30ms/step\n",
      "Epoch 101/150\n",
      "267/267 - 8s - loss: 11.0963 - val_loss: 9.9227 - 8s/epoch - 28ms/step\n",
      "Epoch 102/150\n",
      "267/267 - 8s - loss: 11.0087 - val_loss: 10.4863 - 8s/epoch - 28ms/step\n",
      "Epoch 103/150\n",
      "267/267 - 8s - loss: 11.1621 - val_loss: 9.2161 - 8s/epoch - 29ms/step\n",
      "Epoch 104/150\n",
      "267/267 - 8s - loss: 11.0451 - val_loss: 9.2327 - 8s/epoch - 29ms/step\n",
      "Epoch 105/150\n",
      "267/267 - 8s - loss: 11.0264 - val_loss: 10.2679 - 8s/epoch - 29ms/step\n",
      "Epoch 106/150\n",
      "267/267 - 8s - loss: 11.0286 - val_loss: 9.4844 - 8s/epoch - 28ms/step\n",
      "Epoch 107/150\n",
      "267/267 - 8s - loss: 10.9034 - val_loss: 9.3797 - 8s/epoch - 29ms/step\n",
      "Epoch 108/150\n",
      "267/267 - 8s - loss: 10.7935 - val_loss: 9.6857 - 8s/epoch - 30ms/step\n",
      "Epoch 109/150\n",
      "267/267 - 8s - loss: 10.7876 - val_loss: 9.5966 - 8s/epoch - 29ms/step\n",
      "Epoch 110/150\n",
      "267/267 - 8s - loss: 10.9595 - val_loss: 10.4478 - 8s/epoch - 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2afa23c44eb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add custom callback to stop training if NaN loss is detected\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=64, validation_split=0.3, verbose=2, callbacks=[CustomCallback(), early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56a64295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763/763 [==============================] - 5s 6ms/step\n",
      "191/191 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f54d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert predictions\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train = scaler.inverse_transform(y_train)\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test = scaler.inverse_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09fc2579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSSE: 0.46759127209908874\n",
      "Test RMSSE: 0.3963367169201146\n"
     ]
    }
   ],
   "source": [
    "def calculate_rmsse(actual, predicted):\n",
    "    denominator = np.sqrt(np.mean(np.square(np.diff(actual, axis=0))))\n",
    "    if denominator == 0:\n",
    "        return np.nan\n",
    "    rmsse = np.sqrt(np.mean(np.square(predicted - actual))) / denominator\n",
    "    return rmsse\n",
    "\n",
    "train_rmsse = calculate_rmsse(y_train, train_predict)\n",
    "test_rmsse = calculate_rmsse(y_test, test_predict)\n",
    "\n",
    "print(\"Train RMSSE:\", train_rmsse)\n",
    "print(\"Test RMSSE:\", test_rmsse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a9a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7fd04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
